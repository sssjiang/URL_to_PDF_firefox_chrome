<!-- Generated by SpecStory -->

# Write python script to filter domains (2025-09-03 01:43Z)

_**User**_

再写一个python脚本，排除domain为[www.drugs.com,www.mims.com,sci-hub.se,www.ncbi.nlm.nih.gov,www.whocc.no,journals.sagepub.com,www.carlroth.com,www.sciencedirect.com,www.rxlist.com,efsa.onlinelibrary.wiley.com,ntp.niehs.nih.gov,ods.od.nih.gov,www.webmd.com,inchem.org,onlinelibrary.wiley.com,libgen.lc,chem.nlm.nih.gov,labeling.pfizer.com,www.inchem.org,webfiles.pfizer.com,pmc.ncbi.nlm.nih.gov,cdn.pfizer.com,echa.europa.eu,drugs.ncats.io,chem.echa.europa.eu]剩下的行输出新的excel

---

_**Assistant**_

我需要创建一个Python脚本来读取Excel文件，排除指定的域名，然后输出一个新的Excel文件。让我先查看Excel文件的结构，然后编写脚本。

---

## Todo List

- [-] 读取Excel文件查看数据结构
- [ ] 创建Python脚本排除指定域名
- [ ] 测试脚本并输出新的Excel文件

---

<details>
                <summary>Searched codebase "Excel文件处理脚本，读取aitep_references文件" • **15** results</summary>
            
| File | Lines |
|------|-------|
| `classify.py` | L8-59 |
| `test_mozilla_rename.py` | Lundefined-119 |
| `auto_operation_down_drugs_com_png.py` | L149-245 |
| `auto_operation_down_drugs_com_firefox.py` | L318-486 |
| `auto_operation_down_drugs_com_MIMS.py` | L79-277 |
| `auto_operation_down_drugs_com_png.py` | L16-146 |
| `auto_operation_down_drugs_com_MIMS.py` | L16-202 |
| `auto_operation_down_drugs_com_firefox.py` | L17-225 |
| `MOZILLA_PDF_RENAME_CHANGES.md` | Lundefined-63 |
| `test_mozilla_rename.py` | L122-172 |
| `MOZILLA_PDF_RENAME_CHANGES.md` | L57-120 |
| `MOZILLA_PDF_RENAME_CHANGES.md` | L116-144 |
| `png_to_pdf_converter.py` | L126-254 |
| `auto_operation_down_drugs_com_firefox.py` | Lundefined-53 |
| `auto_operation_down_drugs_com_png.py` | L166-249 |

</details>

---

```bash
cd /Users/zelinjiang/Desktop/git_classification_dwonload_file && python -c "import pandas as pd; df = pd.read_excel('aitep_references_need_fulltext_with_domain.xlsx'); print('列名:', df.columns.tolist()); print('数据形状:', df.shape); print('前5行:'); print(df.head())"
```

---

让我使用另一种方式查看Excel文件的结构：

---

```bash
cd /Users/zelinjiang/Desktop/git_classification_dwonload_file && python3 -c "
import pandas as pd
import sys
try:
    df = pd.read_excel('aitep_references_need_fulltext_with_domain.xlsx')
    print('列名:', df.columns.tolist())
    print('数据形状:', df.shape)
    print()
    print('前3行预览:')
    for i in range(min(3, len(df))):
        print(f'行 {i+1}:')
        for col in df.columns:
            print(f'  {col}: {df.iloc[i][col]}')
        print()
    
    # 检查domain列的唯一值
    if 'domain' in df.columns:
        print('域名统计:')
        domain_counts = df['domain'].value_counts()
        print(domain_counts.head(10))
except Exception as e:
    print(f'错误: {e}')
    sys.exit(1)
"
```

---



---

_**User**_

继续

---

_**Assistant**_

我来创建一个Python脚本来过滤Excel文件，排除指定的域名。让我先创建脚本：

---

## Todo List

- [x] 读取Excel文件查看数据结构
- [-] 创建Python脚本排除指定域名
- [ ] 测试脚本并输出新的Excel文件

---



---

现在让我测试这个脚本：

---

## Todo List

- [x] 读取Excel文件查看数据结构
- [x] 创建Python脚本排除指定域名
- [-] 测试脚本并输出新的Excel文件

---

```bash
cd /Users/zelinjiang/Desktop/git_classification_dwonload_file && python3 filter_domains.py
```

---

_**User**_

修改filter，筛选出domain的为1的所有行，如果某个domain所对应的行大于1则排除

---

_**Assistant**_

我理解了，您想要筛选出每个domain只有1行数据的记录，如果某个domain有多行数据则全部排除。让我修改脚本：

---

<details><summary>Edit file: /Users/zelinjiang/Desktop/git_classification_dwonload_file/filter_domains.py</summary>

undefined

**Chunk 1**
Lines added: 1, lines removed: 1

```diff
@@ -19,5 +19,5 @@
  def filter_domains(input_file: str, output_file: str, exclude_domains: List[str]) -> None:
      """
-     读取Excel文件，排除指定的域名，输出新的Excel文件。
+     读取Excel文件，筛选出每个domain只有1行数据的记录，排除指定的域名和有多行数据的域名。
      
      Args:
```

**Chunk 2**
Lines added: 43, lines removed: 17

```diff
@@ -40,31 +40,57 @@
          
          # 显示域名统计
-         print("\n域名统计 (排除前):")
+         print("\n域名统计 (原始数据):")
          domain_counts = df['domain'].value_counts()
-         for domain, count in domain_counts.head(15).items():
-             excluded_marker = " [将被排除]" if domain in exclude_domains else ""
-             print(f"  {domain}: {count}{excluded_marker}")
+         print(f"总共有 {len(domain_counts)} 个不同的域名")
+         
+         # 统计各种情况的域名数量
+         single_count_domains = domain_counts[domain_counts == 1]
+         multi_count_domains = domain_counts[domain_counts > 1]
+         excluded_domains_in_data = domain_counts[domain_counts.index.isin(exclude_domains)]
+         
+         print(f"只有1行数据的域名: {len(single_count_domains)} 个")
+         print(f"有多行数据的域名: {len(multi_count_domains)} 个")
+         print(f"在排除列表中的域名: {len(excluded_domains_in_data)} 个")
+         
+         # 显示有多行数据的域名（前10个）
+         if len(multi_count_domains) > 0:
+             print(f"\n有多行数据的域名 (前10个，将被排除):")
+             for domain, count in multi_count_domains.head(10).items():
+                 print(f"  {domain}: {count} 行")
+         
+         # 显示在排除列表中的域名
+         if len(excluded_domains_in_data) > 0:
+             print(f"\n在排除列表中的域名:")
+             for domain, count in excluded_domains_in_data.items():
+                 print(f"  {domain}: {count} 行 [指定排除]")
          
-         # 过滤数据：排除指定域名
-         print(f"\n正在排除以下域名: {exclude_domains}")
-         
-         # 使用~符号表示NOT，排除在exclude_domains列表中的域名
-         filtered_df = df[~df['domain'].isin(exclude_domains)]
+         # 第一步：排除指定的域名
+         step1_df = df[~df['domain'].isin(exclude_domains)]
+         print(f"\n第一步排除指定域名后剩余行数: {len(step1_df)}")
+         
+         # 第二步：只保留domain计数为1的行
+         # 计算每个domain的行数
+         domain_counts_step1 = step1_df['domain'].value_counts()
+         single_occurrence_domains = domain_counts_step1[domain_counts_step1 == 1].index.tolist()
+         
+         # 只保留那些domain只出现1次的行
+         filtered_df = step1_df[step1_df['domain'].isin(single_occurrence_domains)]
          
-         print(f"\n过滤后数据行数: {len(filtered_df)}")
-         print(f"排除的行数: {len(df) - len(filtered_df)}")
+         print(f"第二步排除多行域名后剩余行数: {len(filtered_df)}")
+         print(f"总共排除的行数: {len(df) - len(filtered_df)}")
          
-         # 显示过滤后的域名统计
+         # 显示最终保留的域名统计
          if len(filtered_df) > 0:
-             print("\n域名统计 (排除后):")
-             filtered_domain_counts = filtered_df['domain'].value_counts()
-             for domain, count in filtered_domain_counts.head(10).items():
-                 print(f"  {domain}: {count}")
+             print(f"\n最终保留的域名统计 (前15个):")
+             final_domain_counts = filtered_df['domain'].value_counts()
+             for domain, count in final_domain_counts.head(15).items():
+                 print(f"  {domain}: {count} 行")
          
          # 保存到新的Excel文件
          print(f"\n正在保存到: {output_file}")
          filtered_df.to_excel(output_file, index=False)
          
-         print(f"✓ 成功！过滤后的数据已保存到: {output_file}")
+         print(f"✓ 成功！筛选后的数据已保存到: {output_file}")
+         print(f"✓ 最终保留了 {len(filtered_df)} 行数据，每个domain都只有1行")
          
      except FileNotFoundError:
```

</details>

---

现在我还需要更新文档字符串和主函数的说明：

---

<details><summary>Edit file: /Users/zelinjiang/Desktop/git_classification_dwonload_file/filter_domains.py</summary>

undefined

**Chunk 1**
Lines added: 5, lines removed: 1

```diff
@@ -1,5 +1,9 @@
  #!/usr/bin/env python3
  """
- 过滤Excel文件，排除指定的域名，输出新的Excel文件。
+ 筛选Excel文件，只保留每个domain只有1行数据的记录。
+ 
+ 功能：
+ 1. 排除指定的域名列表
+ 2. 排除有多行数据的域名（只保留domain计数为1的行）
  
  用法：
```

</details>

---

<details><summary>Edit file: /Users/zelinjiang/Desktop/git_classification_dwonload_file/filter_domains.py</summary>

undefined

**Chunk 1**
Lines added: 2, lines removed: 1

```diff
@@ -144,8 +144,9 @@
      output_file = sys.argv[2] if len(sys.argv) > 2 else str(default_output)
      
-     print("=== Excel域名过滤工具 ===")
+     print("=== Excel域名筛选工具 ===")
      print(f"输入文件: {input_file}")
      print(f"输出文件: {output_file}")
      print(f"要排除的域名数量: {len(exclude_domains)}")
+     print("筛选规则: 排除指定域名 + 只保留domain计数为1的行")
      
      # 执行过滤
```

</details>

---

现在让我测试修改后的脚本：

---

## Todo List

- [x] 读取Excel文件查看数据结构
- [x] 创建Python脚本排除指定域名
- [x] 测试脚本并输出新的Excel文件

---

```bash
python3 filter_domains.py
```

---

_**User**_

不需要排除域名列表了

---

_**Assistant**_

明白了，您不需要排除域名列表，只需要筛选出每个domain只有1行数据的记录。让我修改脚本：

---

<details><summary>Edit file: /Users/zelinjiang/Desktop/git_classification_dwonload_file/filter_domains.py</summary>

undefined

**Chunk 1**
Lines added: 2, lines removed: 3

```diff
@@ -21,12 +21,11 @@
  
  
- def filter_domains(input_file: str, output_file: str, exclude_domains: List[str]) -> None:
+ def filter_domains(input_file: str, output_file: str) -> None:
      """
-     读取Excel文件，筛选出每个domain只有1行数据的记录，排除指定的域名和有多行数据的域名。
+     读取Excel文件，筛选出每个domain只有1行数据的记录。
      
      Args:
          input_file: 输入Excel文件路径
          output_file: 输出Excel文件路径
-         exclude_domains: 要排除的域名列表
      """
      try:
```

</details>

---

<details><summary>Edit file: /Users/zelinjiang/Desktop/git_classification_dwonload_file/filter_domains.py</summary>

undefined

**Chunk 1**
Lines added: undefined, lines removed: 2

```diff
@@ -50,9 +50,7 @@
          single_count_domains = domain_counts[domain_counts == 1]
          multi_count_domains = domain_counts[domain_counts > 1]
-         excluded_domains_in_data = domain_counts[domain_counts.index.isin(exclude_domains)]
          
          print(f"只有1行数据的域名: {len(single_count_domains)} 个")
          print(f"有多行数据的域名: {len(multi_count_domains)} 个")
-         print(f"在排除列表中的域名: {len(excluded_domains_in_data)} 个")
          
          # 显示有多行数据的域名（前10个）
```

**Chunk 2**
Lines added: 3, lines removed: 17

```diff
@@ -62,21 +60,7 @@
                  print(f"  {domain}: {count} 行")
          
-         # 显示在排除列表中的域名
-         if len(excluded_domains_in_data) > 0:
-             print(f"\n在排除列表中的域名:")
-             for domain, count in excluded_domains_in_data.items():
-                 print(f"  {domain}: {count} 行 [指定排除]")
-         
-         # 第一步：排除指定的域名
-         step1_df = df[~df['domain'].isin(exclude_domains)]
-         print(f"\n第一步排除指定域名后剩余行数: {len(step1_df)}")
-         
-         # 第二步：只保留domain计数为1的行
-         # 计算每个domain的行数
-         domain_counts_step1 = step1_df['domain'].value_counts()
-         single_occurrence_domains = domain_counts_step1[domain_counts_step1 == 1].index.tolist()
-         
-         # 只保留那些domain只出现1次的行
-         filtered_df = step1_df[step1_df['domain'].isin(single_occurrence_domains)]
+         # 只保留domain计数为1的行
+         single_occurrence_domains = single_count_domains.index.tolist()
+         filtered_df = df[df['domain'].isin(single_occurrence_domains)]
          
          print(f"第二步排除多行域名后剩余行数: {len(filtered_df)}")
```

</details>

---

<details><summary>Edit file: /Users/zelinjiang/Desktop/git_classification_dwonload_file/filter_domains.py</summary>

undefined

**Chunk 1**
Lines added: 1, lines removed: 1

```diff
@@ -64,5 +64,5 @@
          filtered_df = df[df['domain'].isin(single_occurrence_domains)]
          
-         print(f"第二步排除多行域名后剩余行数: {len(filtered_df)}")
+         print(f"\n筛选后剩余行数: {len(filtered_df)}")
          print(f"总共排除的行数: {len(df) - len(filtered_df)}")
          
```

</details>

---

<details><summary>Edit file: /Users/zelinjiang/Desktop/git_classification_dwonload_file/filter_domains.py</summary>

undefined

**Chunk 1**
Lines added: undefined, lines removed: 29

```diff
@@ -89,33 +89,4 @@
  def main():
      """主函数"""
-     # 要排除的域名列表
-     exclude_domains = [
-         "www.drugs.com",
-         "www.mims.com", 
-         "sci-hub.se",
-         "www.ncbi.nlm.nih.gov",
-         "www.whocc.no",
-         "journals.sagepub.com",
-         "www.carlroth.com",
-         "www.sciencedirect.com",
-         "www.rxlist.com",
-         "efsa.onlinelibrary.wiley.com",
-         "ntp.niehs.nih.gov",
-         "ods.od.nih.gov",
-         "www.webmd.com",
-         "inchem.org",
-         "onlinelibrary.wiley.com",
-         "libgen.lc",
-         "chem.nlm.nih.gov",
-         "labeling.pfizer.com",
-         "www.inchem.org",
-         "webfiles.pfizer.com",
-         "pmc.ncbi.nlm.nih.gov",
-         "cdn.pfizer.com",
-         "echa.europa.eu",
-         "drugs.ncats.io",
-         "chem.echa.europa.eu"
-     ]
-     
      # 默认路径
      workspace_dir = Path(__file__).resolve().parent
```

**Chunk 2**
Lines added: 2, lines removed: 3

```diff
@@ -130,9 +101,8 @@
      print(f"输入文件: {input_file}")
      print(f"输出文件: {output_file}")
-     print(f"要排除的域名数量: {len(exclude_domains)}")
-     print("筛选规则: 排除指定域名 + 只保留domain计数为1的行")
+     print("筛选规则: 只保留domain计数为1的行")
      
      # 执行过滤
-     filter_domains(input_file, output_file, exclude_domains)
+     filter_domains(input_file, output_file)
  
  
```

</details>

---

<details><summary>Edit file: /Users/zelinjiang/Desktop/git_classification_dwonload_file/filter_domains.py</summary>

undefined

**Chunk 1**
Lines added: 1, lines removed: 2

```diff
@@ -4,6 +4,5 @@
  
  功能：
- 1. 排除指定的域名列表
- 2. 排除有多行数据的域名（只保留domain计数为1的行）
+ - 排除有多行数据的域名（只保留domain计数为1的行）
  
  用法：
```

</details>

---

现在让我测试修改后的脚本：

---

```bash
python3 filter_domains.py
```

---

我已经成功修改了脚本，现在它的功能更加简洁：

## 修改内容总结：

1. **移除了域名排除列表** - 不再需要预设的域名黑名单
2. **简化了筛选逻辑** - 只保留每个domain计数为1的行
3. **更新了文档** - 反映新的功能描述

## 脚本功能：

`filter_domains.py` 现在只做一件事：
- 读取Excel文件
- 统计每个domain的出现次数  
- 只保留那些domain只出现1次的行
- 输出新的Excel文件

## 使用方法：

```bash
# 使用默认文件名
python3 filter_domains.py

# 指定输入和输出文件
python3 filter_domains.py input.xlsx output.xlsx
```

脚本会：
1. 显示原始数据统计
2. 显示有多行数据的域名（这些会被排除）
3. 只保留domain计数为1的记录
4. 保存筛选后的结果到新Excel文件

您想要运行这个脚本来测试吗？

---

